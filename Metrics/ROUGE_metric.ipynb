{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class ROUGE:\n",
    "    def __init__(self, ngram_size: int):\n",
    "        self.ngram_size = ngram_size\n",
    "    \n",
    "    def _get_ngrams(self, text: str) -> List[str]:\n",
    "        words = text.split()\n",
    "        ngrams = []\n",
    "        for i in range(len(words) - self.ngram_size + 1):\n",
    "            ngrams.append(\" \".join(words[i:i+self.ngram_size]))\n",
    "        return ngrams\n",
    "    \n",
    "    def _compute_recall(self, ref_text: str, eval_text: str) -> float:\n",
    "        ref_ngrams = set(self._get_ngrams(ref_text))\n",
    "        eval_ngrams = set(self._get_ngrams(eval_text))\n",
    "        intersection = ref_ngrams.intersection(eval_ngrams)\n",
    "        return len(intersection) / len(ref_ngrams)\n",
    "    \n",
    "    def _compute_precision(self, ref_text: str, eval_text: str) -> float:\n",
    "        ref_ngrams = set(self._get_ngrams(ref_text))\n",
    "        eval_ngrams = set(self._get_ngrams(eval_text))\n",
    "        intersection = ref_ngrams.intersection(eval_ngrams)\n",
    "        return len(intersection) / len(eval_ngrams)\n",
    "    \n",
    "    def compute_score(self, reference_texts: List[str], evaluation_text: str) -> float:\n",
    "        recall_sum = 0.0\n",
    "        precision_sum = 0.0\n",
    "        for ref_text in reference_texts:\n",
    "            recall_sum += self._compute_recall(ref_text, evaluation_text)\n",
    "            precision_sum += self._compute_precision(ref_text, evaluation_text)\n",
    "        recall = recall_sum / len(reference_texts)\n",
    "        precision = precision_sum / len(reference_texts)\n",
    "        if recall + precision == 0:\n",
    "            return 0.0\n",
    "        f1_score = 2.0 * (precision * recall) / (precision + recall)\n",
    "        return f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 score: 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "reference_texts = [\"i love my dog\", \"i am a bjj player\"]\n",
    "evaluation_text = \"a cat is sitting on the mat\"\n",
    "\n",
    "rouge_1 = ROUGE(ngram_size=1)\n",
    "score = rouge_1.compute_score(reference_texts, evaluation_text)\n",
    "\n",
    "print(\"ROUGE-1 score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-2 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "rouge_2 = ROUGE(ngram_size=2)\n",
    "score = rouge_2.compute_score(reference_texts, evaluation_text)\n",
    "\n",
    "print(\"ROUGE-2 score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
